# Databricks notebook source
# MAGIC %md
# MAGIC
# MAGIC <div style="text-align: center; line-height: 0; padding-top: 9px;">
# MAGIC   <img src="https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png" alt="Databricks Learning">
# MAGIC </div>
# MAGIC

# COMMAND ----------

# MAGIC %md
# MAGIC # Caso de uso moderno: Reposit√≥rio de recursos na Databricks
# MAGIC Nesta demonstra√ß√£o, abordaremos o processo de uso do reposit√≥rio de recursos do Databricks para criar, treinar e implantar modelos de machine learning usando recursos armazenados em um reposit√≥rio centralizado. Abordaremos a instala√ß√£o das bibliotecas necess√°rias, a cria√ß√£o e atualiza√ß√£o de recursos, o treinamento de um modelo com esses recursos e a realiza√ß√£o de infer√™ncia em lote para fazer previs√µes. Ao final desta demonstra√ß√£o, voc√™ ganhar√° experi√™ncia pr√°tica ao aproveitar o poder do reposit√≥rio de recursos do Databricks para simplificar os fluxos de trabalho de machine learning e garantir consist√™ncia no gerenciamento de recursos.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Objetivos de Aprendizagem 
# MAGIC Ao final desta demonstra√ß√£o, voc√™ ser√° capaz de:
# MAGIC - Aplicar o processo de instala√ß√£o e configura√ß√£o das bibliotecas da Reposit√≥rio de recursos do Databricks.
# MAGIC - Criar e gerenciar tabelas de recursos no Databricks para armazenar e atualizar recursos.
# MAGIC - Treinar um modelo de machine learning usando recursos recuperadas da Reposit√≥rio de recursos.
# MAGIC - Realizar infer√™ncia em lote para gerar previs√µes com base em dados de recursos.
# MAGIC - Avaliar a efic√°cia das atualiza√ß√µes peri√≥dicas de recursos para manter a precis√£o do modelo.

# COMMAND ----------

# MAGIC %md
# MAGIC ## üö®OBRIGAT√ìRIO - SELECT CLASSIC COMPUTE
# MAGIC Antes de executar c√©lulas neste notebook, selecione seu cluster de compute cl√°ssico no laborat√≥rio. Lembre-se de que **Serverless** est√° habilitado por default.
# MAGIC
# MAGIC Siga estas etapas para selecionar o cluster de compute cl√°ssico:
# MAGIC * Navegue at√© o canto superior direito deste notebook e clique no menu dropdown para selecionar seu cluster. Por default, o notebook usar√° **Serverless**. <br>
# MAGIC
# MAGIC ##### **üìå**Se o cluster estiver dispon√≠vel, selecione-o e continue para a pr√≥xima c√©lula. Se o cluster n√£o for mostrado:
# MAGIC   - Na lista dropdown, selecione **More**.
# MAGIC   - No pop-up **Attach to an existing compute resource**, selecione a primeira lista dropdown. Voc√™ ver√° um nome de cluster exclusivo nessa lista dropdown. Selecione esse cluster.
# MAGIC
# MAGIC **NOTA:** Se o cluster tiver sido encerrado, talvez seja necess√°rio reinici√°-lo para selecion√°-lo. Para fazer isso:
# MAGIC 1. Clique com o bot√£o direito do rato em **Compute** no painel de navega√ß√£o esquerdo e selecione *Open in new tab*.
# MAGIC 2. Localize o √≠cone de tri√¢ngulo √† direita do nome do cluster de compute e clique nele.
# MAGIC 3. Aguarde alguns minutos para que o cluster seja iniciado.
# MAGIC 4. Quando o cluster estiver em execu√ß√£o, conclua as etapas acima para selecion√°-lo.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Requisitos
# MAGIC
# MAGIC Analise os seguintes requisitos antes de iniciar a demonstra√ß√£o:
# MAGIC
# MAGIC * Para executar este notebook, voc√™ precisa usar um dos seguintes Databricks runtime(s): **15.4.x-scala2.12**
# MAGIC * Como alternativa, em um cluster de tempo de execu√ß√£o n√£o-ML, instale manualmente as bibliotecas necess√°rias de maneira semelhante. (Para esta demonstra√ß√£o, temos um cluster n√£o-ML)

# COMMAND ----------

# MAGIC %md
# MAGIC ### Tarefas do Notebook:
# MAGIC Este Notebook orienta o processo de:
# MAGIC 1. **Installing Libraries** para reposit√≥rio de recursos do Databricks.
# MAGIC 2. **Building Features** e salvando-os no reposit√≥rio de recursos.
# MAGIC 3. **Training a Model** usando esses recursos.
# MAGIC 4. **Performing Batch Inference** com os mesmos recursos.

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Instalar bibliotecas necess√°rias
# MAGIC
# MAGIC Instalaremos a biblioteca Engenharia de recursos da Databricks (tamb√©m conhecida como reposit√≥rio de recursos) para que possamos criar defini√ß√µes de tabela, carregar conjuntos de treinamento e publicar recursos.

# COMMAND ----------

# MAGIC %pip install databricks-feature-engineering

# COMMAND ----------

# MAGIC %md
# MAGIC Uma vez que a biblioteca √© instalada, reiniciamos o kernel Python para que ele esteja totalmente dispon√≠vel.

# COMMAND ----------

dbutils.library.restartPython()

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Configura√ß√£o do ambiente
# MAGIC
# MAGIC - Vamos trabalhar em um cat√°logo e esquema a que voc√™ tem acesso.
# MAGIC - Ajuste os nomes do cat√°logo/esquema para corresponder ao seu ambiente ou conven√ß√µes de nomenclatura.

# COMMAND ----------

import re
from databricks.feature_store import FeatureStoreClient

fs = FeatureStoreClient()


user_id = spark.sql("SELECT current_user()").collect()[0][0].split("@")[0]
catalog_name = re.sub(r'[^a-zA-Z0-9]', '_', user_id)
silver_schema = "silver"
gold_schema = "gold"

spark.sql(f"USE CATALOG {catalog_name}")
spark.sql(f"USE {silver_schema}")

print("Catalog and schemas set for feature development.")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Criando ou atualizando recursos
# MAGIC
# MAGIC **Objetivo**: Crie recursos no n√≠vel do cliente a partir de tabelas refinadas de exemplo (`refined_orders` e `refined_customer`):
# MAGIC - `total_orders`: N√∫mero total de pedidos por cliente
# MAGIC - `avg_order_value`: Pre√ßo m√©dio por pedido
# MAGIC - `total_spending`: Valor total gasto no geral
# MAGIC - `market_segment`: Uma coluna categ√≥rica da dimens√£o Cliente

# COMMAND ----------

# Gere recursos b√°sicos no n√≠vel do cliente agregando dados do pedido e juntando com as informa√ß√µes do cliente
from pyspark.sql.functions import col, count, avg, sum, current_timestamp

orders_df = spark.sql("SELECT * FROM refined_orders")
customers_df = spark.sql("SELECT * FROM refined_customer")

base_features_df = (
    orders_df.groupBy("customer_id")
    .agg(
        count("*").alias("total_orders"),
        avg("total_price").alias("avg_order_value"),
        sum("total_price").alias("total_spending")
    )
    .join(
        customers_df.select("customer_id", "market_segment"),
        on="customer_id",
        how="inner"
    )
    .withColumn("feature_update_ts", current_timestamp())
)

display(base_features_df.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC ### 3.1 Registrar ou Mesclar-Atualizar Tabela de Recursos
# MAGIC
# MAGIC Criaremos uma tabela de recursos chamada `customer_features` no esquema `gold`. Se j√° existir, mesclaremos os novos dados.

# COMMAND ----------

# Criar ou mesclar-atualizar a tabela 'customer_features' com recursos agregados no n√≠vel do cliente
feature_table_name = f"{catalog_name}.{gold_schema}.customer_features"

try:
    fs.create_table(
        name=feature_table_name,
        primary_keys=["customer_id"],
        schema=base_features_df.schema,
        description="Customer-level features derived from refined tables."
    )
    print(f"Feature table '{feature_table_name}' created.")
except Exception as e:
    print(f"Feature table might already exist: {e}")

fs.write_table(
    name=feature_table_name,
    df=base_features_df,
    mode="merge"  
)

print(f"Feature table '{feature_table_name}' updated with new features.")

# COMMAND ----------

# MAGIC %md
# MAGIC ### 3.2 Agendando atualiza√ß√µes
# MAGIC
# MAGIC Este notebook (ou um subconjunto dele) pode ser agendado como um Databricks Job para atualizar periodicamente os recursos com dados atualizados. Isso garante que seus recursos permane√ßam atualizados para tarefas de ML downstream.

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Treinamento de modelos com o Reposit√≥rio de recursos
# MAGIC
# MAGIC Vamos fazer o seguinte:
# MAGIC 1. Crie um r√≥tulo simples: Os clientes que gastaram mais do que um determinado limite s√£o considerados "grandes gastadores."
# MAGIC 2. Procure os mesmos recursos via `FeatureLookup` para treinamento.
# MAGIC 3. Treinar um modelo b√°sico de Regress√£o Log√≠stica.

# COMMAND ----------

# Adicionar r√≥tulo bin√°rio aos clientes com base em se seus gastos totais excedem um limite
from pyspark.sql.functions import when

threshold = 20000.0

labeled_df = (
    base_features_df
    .withColumn("label", when(col("total_spending") > threshold, 1).otherwise(0))
    .select("customer_id", "total_orders", "avg_order_value", "total_spending", "market_segment", "label")
)

display(labeled_df.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC ### 4.1 Criar um conjunto de treinamento com FeatureLookups
# MAGIC
# MAGIC Use uma pesquisa para recuperar colunas da tabela de recursos e associ√°-las ao nosso dataset rotulado.

# COMMAND ----------

# Crie um conjunto de treinamento pesquisando recursos do reposit√≥rio de recursos e juntando-os com dados rotulados
from databricks.feature_store import FeatureLookup

feature_lookup = FeatureLookup(
    table_name=feature_table_name,
    feature_names=[
        "total_orders",
        "avg_order_value",
        "total_spending",
        "market_segment",
    ],
    lookup_key="customer_id",
)
labeled_df_clean = labeled_df.drop("total_orders", "avg_order_value", "total_spending", "market_segment")

training_set = fs.create_training_set(
    df=labeled_df_clean,
    feature_lookups=[feature_lookup],
    label="label",
    exclude_columns=["feature_update_ts"]
)

training_df = training_set.load_df()
display(training_df.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC ### 4.2 Treinar um Modelo de Regress√£o Log√≠stica Simples
# MAGIC
# MAGIC Vamos converter a coluna `market_segment` categ√≥rica em forma num√©rica, vetorizar todos os recursos e treinar um classificador bin√°rio.

# COMMAND ----------

# Construir e treinar um modelo de regress√£o log√≠stica usando um pipeline com etapas de transforma√ß√£o de recursos
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml import Pipeline

# Indexador de string para a coluna categ√≥rica
indexer = StringIndexer(inputCol="market_segment", outputCol="market_segment_idx", handleInvalid="keep")
encoder = OneHotEncoder(inputCols=["market_segment_idx"], outputCols=["market_segment_vec"])

assembler = VectorAssembler(
    inputCols=["total_orders", "avg_order_value", "total_spending", "market_segment_vec"],
    outputCol="features"
)

lr = LogisticRegression(featuresCol="features", labelCol="label", maxIter=10)

pipeline = Pipeline(stages=[indexer, encoder, assembler, lr])
model = pipeline.fit(training_df)

print("Model training complete.")

# COMMAND ----------

# MAGIC %md
# MAGIC ### 4.3 (opcional) Registrar modelo no MLflow
# MAGIC
# MAGIC Se voc√™ quiser acompanhar vers√µes, m√©tricas e implantar o modelo facilmente, registre-o no MLflow. Por uma quest√£o de brevidade, vamos omitir esses detalhes aqui.

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Infer√™ncia em lote usando o Reposit√≥rio de recursos
# MAGIC
# MAGIC **Cen√°rio**: Temos alguns IDs de clientes novos ou existentes e queremos prever quais podem ser os que gastam muito. Vamos fazer:
# MAGIC 1. Demonstrar a cria√ß√£o de um DataFrame de IDs de clientes.
# MAGIC 2. Procure os mesmos recursos via `FeatureLookup`.
# MAGIC 3. Gere previs√µes com nosso pipeline treinado.

# COMMAND ----------

# Selecione 5 clientes de amostra e adicione uma coluna de sinalizador para demonstra√ß√£o de infer√™ncia em lote
from pyspark.sql.functions import lit

sample_customers = (
    training_df.select("customer_id")
    .limit(5)
    .withColumn("batch_inference_example", lit(True))
)

display(sample_customers)

# COMMAND ----------

# MAGIC %md
# MAGIC ### 5.1 Recuperar recursos e pontuar
# MAGIC
# MAGIC A fus√£o dos clientes preparados com nossa tabela de recursos resulta em um DataFrame final que pode ser executado atrav√©s do modelo.

# COMMAND ----------

# Realizar infer√™ncia em lotes recuperando recursos para clientes de amostra e aplicando o modelo treinado
inference_lookup = FeatureLookup(
    table_name=feature_table_name,
    feature_names=[
        "total_orders",
        "avg_order_value",
        "total_spending",
        "market_segment"
    ],
    lookup_key="customer_id"
)

inference_set = fs.create_training_set(
    df=sample_customers,
    feature_lookups=[inference_lookup],
    label=None 
)

inference_df = inference_set.load_df()
predictions = model.transform(inference_df)
display(predictions.select("customer_id", "prediction", "probability"))

# COMMAND ----------

# MAGIC %md
# MAGIC ### Principais conceitos abordados:
# MAGIC - **Periodic Feature Updates** mant√™m os recursos de entrada do seu modelo atualizados.
# MAGIC - **Single Source of Truth** para recursos via reposit√≥rio de recursos leva a treinamento consistente e infer√™ncia.
# MAGIC - **Batch or Real-Time Inference** pode ser implementada usando as mesmas defini√ß√µes de recursos.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Conclus√£o
# MAGIC Nesta demonstra√ß√£o, implementamos com sucesso um pipeline completo usando o reposit√≥rio de recursos da Databricks para gerenciar, treinar e prever com recursos de machine learning. Criamos e atualizamos tabelas de recursos, treinamos um modelo usando esses recursos e realizamos infer√™ncias em lote para fazer previs√µes. Seguindo esse fluxo de trabalho, voc√™ pode garantir consist√™ncia e efici√™ncia no gerenciamento de recursos, permitindo que voc√™ crie e implante modelos de machine learning mais confi√°veis. Etapas futuras podem incluir a implementa√ß√£o de infer√™ncia em tempo real ou a automatiza√ß√£o de atualiza√ß√µes de recursos para fluxos de trabalho de dados mais din√¢micos.

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC &copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href="https://www.apache.org/">Apache Software Foundation</a>.<br/>
# MAGIC <br/><a href="https://databricks.com/privacy-policy">Privacy Policy</a> | 
# MAGIC <a href="https://databricks.com/terms-of-use">Terms of Use</a> | 
# MAGIC <a href="https://help.databricks.com/">Support</a>
